{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import model_selection\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from urllib.parse import urlparse\n",
    "from sklearn import preprocessing\n",
    "import tldextract\n",
    "%matplotlib inline\n",
    "import random\n",
    "import gc\n",
    "import xgboost as xgb\n",
    "from sklearn import svm\n",
    "from tensorflow import keras\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 100\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "\n",
    "random.seed(SEED)\n",
    "\n",
    "np.random.seed(SEED)\n",
    "\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/Users/abhinavshinow/Documents/GitHub/Mal_URL/Data/mal_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type']=df['type'].replace({'phishing':1,'benign':0,'defacement':2,'malware':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Extraction methods\n",
    "\n",
    "#Checks for https in the string\n",
    "def has_https(s):\n",
    "    scheme = urlparse(s).scheme\n",
    "    if(scheme==''):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1    \n",
    "\n",
    "#returns the count of www in the url\n",
    "def www(s):\n",
    "    return s.count('www')\n",
    "\n",
    "#returns the count of digits in the url\n",
    "def digit(s):\n",
    "    return sum(i.isnumeric() for i in s)\n",
    "\n",
    "#returns the count of alphabets in the url\n",
    "def alpha(s):\n",
    "    return sum(i.isalpha() for i in s)\n",
    "\n",
    "#returns the count of special character's in the url\n",
    "def spec_char(s):\n",
    "    return sum((not(i.isalpha()) and not(i.isnumeric())) for i in s)\n",
    "\n",
    "def punctuation_count(s):\n",
    "    list = ['.','!','#','$','%','&',',',':']\n",
    "\n",
    "#returns 1 if the url contains a //\n",
    "def double_slash(s):\n",
    "    if(s.count('//')>0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#returns the count of / in the url\n",
    "def spec_char_1(s):\n",
    "    return s.count('/')\n",
    "\n",
    "#returns the count of ! in the url\n",
    "def spec_char_2(s):\n",
    "    return s.count('!')\n",
    "\n",
    "#returns the count of . in the url\n",
    "def spec_char_3(s):\n",
    "    return s.count('.')\n",
    "\n",
    "#returns the count of @ in the url    \n",
    "def spec_char_4(s):\n",
    "    return s.count('@')\n",
    "\n",
    "#returns the count of % in the url\n",
    "def spec_char_5(s):\n",
    "    return s.count('%')\n",
    "\n",
    "#returns the count of ? in the url\n",
    "def spec_char_6(s):\n",
    "    return s.count('?')\n",
    "\n",
    "#returns the count of = in the url\n",
    "def spec_char_7(s):\n",
    "    return s.count('=')\n",
    "\n",
    "#returns the count of + in the url\n",
    "def spec_char_8(s):\n",
    "    return s.count('+')\n",
    "\n",
    "#returns the count of - in the url\n",
    "def spec_char_9(s):\n",
    "    return s.count('-')\n",
    "\n",
    "#returns the count of & in the url\n",
    "def spec_char_10(s):\n",
    "    return s.count('&')\n",
    "    \n",
    "#returns the count of & in the url\n",
    "def spec_char_11(s):\n",
    "    return s.count('~')\n",
    "\n",
    "#returns the length of the query if it contains a query\n",
    "def query_length(s):\n",
    "    return len(urlparse(s).query)\n",
    "\n",
    "#returns the domain of the url\n",
    "def dom_suffix(s):\n",
    "    domains={'com':1,'edu':2,'org':3,'net':4,'onion':5,'in':6}\n",
    "    s=tldextract.extract(s).suffix\n",
    "    if s in domains.keys():\n",
    "        return domains[s]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#returns the length of the domain\n",
    "def dom_length(s):\n",
    "    return len(tldextract.extract(s).domain)\n",
    "\n",
    "#returns the length of the sub_domain\n",
    "def subdom_length(s):\n",
    "    return len(tldextract.extract(s).subdomain)\n",
    "\n",
    "#returns the length of the url path\n",
    "def path_length(s):\n",
    "    return len(urlparse(s).path)\n",
    "\n",
    "#returns 1 if url contains a query\n",
    "def has_query(s):\n",
    "    if len(urlparse(s).query)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "#Check's for an ip within the url\n",
    "def ip(s):\n",
    "    has_ip=re.search('(([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.'\n",
    "    '([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\/)|'  # IPv4\n",
    "    '((0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\/)' # IPv4 in hexadecimal\n",
    "    '(?:[a-fA-F0-9]{1,4}:){7}[a-fA-F0-9]{1,4}', s)\n",
    "    if has_ip:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "#Checks for extensions within the url\n",
    "def extension(s):\n",
    "    if '.htm' in s:\n",
    "        return 1\n",
    "    elif '.html' in s:\n",
    "        return 2\n",
    "    elif '.js' in s:\n",
    "        return 3\n",
    "    elif '.css' in s:\n",
    "        return 4\n",
    "    elif '.exe' in s:\n",
    "        return 5\n",
    "    elif '.php' in s:\n",
    "        return 6\n",
    "    elif '.py' in s:\n",
    "        return 7\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['len']=df['url'].apply(lambda s : len(str(s)))\n",
    "\n",
    "df['https'] = df['url'].apply(lambda s : has_https(s))\n",
    "\n",
    "df['www'] = df['url'].apply(lambda s : www(s))\n",
    "\n",
    "df['digit_count'] = df['url'].apply(lambda s: digit(s))\n",
    "\n",
    "df['alpha_count'] = df['url'].apply(lambda s: alpha(s))\n",
    "\n",
    "df['spec_char_count'] = df['url'].apply(lambda s: spec_char(s))\n",
    "\n",
    "df['puntuation_count'] = df['url'].apply(lambda s: punctuation_count(s))\n",
    "\n",
    "df['double_slash'] = df['url'].apply(lambda s: double_slash(s))\n",
    "\n",
    "df['/'] = df['url'].apply(lambda s: spec_char_1(s))\n",
    "\n",
    "df['!'] = df['url'].apply(lambda s: spec_char_2(s))\n",
    "\n",
    "df['.'] = df['url'].apply(lambda s: spec_char_3(s))\n",
    "\n",
    "df['@'] = df['url'].apply(lambda s: spec_char_4(s))\n",
    "\n",
    "df['%'] = df['url'].apply(lambda s: spec_char_5(s))\n",
    "\n",
    "df['?'] = df['url'].apply(lambda s: spec_char_6(s))\n",
    "\n",
    "df['='] = df['url'].apply(lambda s: spec_char_7(s))\n",
    "\n",
    "df['+'] = df['url'].apply(lambda s: spec_char_8(s))\n",
    "\n",
    "df['-'] = df['url'].apply(lambda s: spec_char_9(s))\n",
    "\n",
    "df['&'] = df['url'].apply(lambda s: spec_char_10(s))\n",
    "\n",
    "df['~'] = df['url'].apply(lambda s: spec_char_11(s))\n",
    "\n",
    "df['dom_suffix'] = df['url'].apply(lambda s: dom_suffix(s))\n",
    "\n",
    "df['dom_length'] = df['url'].apply(lambda s: dom_length(s))\n",
    "\n",
    "df['subdom_length'] = df['url'].apply(lambda s: subdom_length(s))\n",
    "\n",
    "df['path_length'] = df['url'].apply(lambda s: path_length(s))\n",
    "\n",
    "df['query_length'] = df['url'].apply(lambda s: query_length(s))\n",
    "\n",
    "df['ip'] = df['url'].apply(lambda s: ip(s))\n",
    "\n",
    "df['extension'] = df['url'].apply(lambda s: extension(s))\n",
    "\n",
    "df.drop('url',axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:461: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:462: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n"
     ]
    }
   ],
   "source": [
    "#Normalising the feauture values to between 0 and 1\n",
    "x=['len','https','www','digit_count','alpha_count','spec_char_count','puntuation_count','double_slash','/','!','.','@','%','?','=','+','-','&','~','dom_suffix','dom_length','subdom_length','path_length','query_length','extension','ip']\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "column_names_to_normalize = x\n",
    "x = df[column_names_to_normalize].values\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index = df.index)\n",
    "df[column_names_to_normalize] = df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df[['len','https','www','digit_count','alpha_count','spec_char_count','puntuation_count','double_slash','/','!','.','@','%','?','=','+','-','&','~','dom_suffix','dom_length','subdom_length','path_length','query_length','extension','ip']]\n",
    "y=df['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,shuffle='True',stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6t/fjr9gh2x3kzfp_x8d04mv8gm0000gn/T/ipykernel_5658/46410455.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Logistic Regression Classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1506\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1508\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m   1509\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m    957\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    112\u001b[0m         ):\n\u001b[1;32m    113\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"infinity\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"NaN, infinity\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    115\u001b[0m                 msg_err.format(\n\u001b[1;32m    116\u001b[0m                     \u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "#Logistic Regression Classifier\n",
    "model=LogisticRegression(solver='lbfgs',max_iter=1000)\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(x_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tensorflow': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
